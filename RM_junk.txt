
"""
# N qubit IS purity
for ii in range(nu):
    I_mh += X_mh[ii]*exp_dnn*counts[ii]/X_is[ii,0]/np.sum(counts)
    
Purity_mc[trial] = I_mc
Purity_mh[trial] = I_mh

## made a modification
# Error in purity for 2 qubit GHZ state     
Error_mh[trial] = np.abs((I_mh-purity))/purity  
#Error_mc_check[trial] = np.abs((I_mc_check-purity)/purity) 
Error_mc[trial] = np.abs((I_mc-purity))/purity

for trial in range(experiments):

# calling metropolis sampling
var, accept, counter, X_mps = metropolis_sampling(N, angles,nu, burn_in)

# total number of samples accepted during metropolis
accept = len(np.unique(var[:,0]))

accept_ratio += (accept/counter)/experiments
#print(accept_ratio)

# defines non repetative sampples given by metropolis
new_samples = np.zeros((nu_tot, angles*N))    
X_is = np.zeros((nu_tot, 1)) 

for ii in range(angles*N):
indexes = np.unique(var[:,ii], return_index=True)[1]
new_samples[:,ii] = np.array([var[:,ii][index] for index in sorted(indexes)])


indexes = np.unique(X_mps, return_index=True)[1]
if (round(purity,6) == 2**(-N)):
X_is = 2**(-N)*np.ones((nu_tot,1))
else:    
X_is[:,0] = np.array([X_mps[index] for index in sorted(indexes)])            
# counts the number of occurence of each sample generated by metropolis
counts = [list(var[:,0]).count(i) for i in new_samples[:,0]]

# burn_in
new_samples = np.delete(new_samples, list(np.arange(0,int(burn_in*nu),1)), axis = 0)
counts = np.delete(counts, list(np.arange(0,int(burn_in*nu),1)), axis = 0)

# imprtance sampling weights
X_is = np.delete(X_is, list(np.arange(0,int(burn_in*nu),1)), axis = 0)
  
new_samples = np.transpose(new_samples)

# RM using importance sampled angles 
#X_dnn = RM(N,rho_mps,nu,new_samples[0:N,:],new_samples[N:2*N,:])

X_mh = RM_sn_RAM(N,rho_traced,nu,nm,new_samples[0:N,:],new_samples[N:2*N,:])

I_mh = 0
I_mc = 0

theta_1 = np.zeros((N,nu)) # last rotation along z 
theta_2 = np.array(random_gen.rand(N,nu)) # rotation along y
theta_3 = np.array(random_gen.rand(N,nu)) # this is the first rotation along z that is applied

## RM using uniform sampling
X_2 = RM_sn_RAM(N,rho_traced,nu,nm,theta_2,theta_3)

# N qubit MC purity  
I_mc = np.mean(X_2)

# N qubit IS purity
for ii in range(nu):
I_mh += X_mh[ii]*exp_dnn*counts[ii]/X_is[ii,0]/np.sum(counts)

Purity_mc[trial] = I_mc
Purity_mh[trial] = I_mh


# Error in purity for 2 qubit GHZ state     
Error_mh[trial] = np.abs((I_mh-purity))/purity  
#Error_mc_check[trial] = np.abs((I_mc_check-purity)/purity) 
Error_mc[trial] = np.abs((I_mc-purity))/purity                                                                                                                                                             



## defining the intervals to sample the Y random rotation
xi_a = 0
xi_b = 1 

## Intervals to sample the Z random rotation
phi_a = 0
phi_b = 2*math.pi 


def  countSetBits(n): 
count = 0
while (n): 
count += n & 1
n >>= 1
return count 

## Randomized meaurement function without shot noise to provide X
def RM(NN,rho_rm, nu, xi, phi):   

bitcount = np.zeros((1,2**NN))
for ii in range(2**NN):
bitcount[:,ii] = (-2.)**(-countSetBits(ii))

## Interval of integration for the unitary angles \xi, \alpha and \psi
xi_b = 1
psi_b = 2*math.pi
alpha_b = 2*math.pi

## Vector of all the values of the function X
X = np.zeros((NN, nu))

partition_string_system = ['1'*x +'0'*(NN-x) for x in range(1,NN+1)]
partition_system = np.array([int(p,2) for p in partition_string_system])

for iu in range(nu):

probb = np.zeros((1, 2**NN))
uf = [1]
u_temp = 1j*(np.zeros((NN,2,2)))

for qubits in range(NN):

## preparing the unitary angles \alpha and \psi
alpha = 0
psi = 0
alpha = (-phi[qubits, iu])*alpha_b
psi = (phi[qubits,iu])*psi_b
u_temp[qubits,:,:] = (np.array([[math.sqrt(1-xi[qubits,iu])*cmath.exp(1j*alpha), math.sqrt(xi[qubits, iu])*cmath.exp(1j*psi)] , [-math.sqrt(xi[qubits, iu])*cmath.exp(-1j*psi), math.sqrt(1-xi[qubits, iu])*cmath.exp(-1j*alpha)]], dtype = complex))

## final unitary u = \otimes u_i 
uf = 1j*(np.kron(uf,u_temp[qubits,:,:]))

## probabilities obtained by performing the randomized measurements on \rho
probb = np.real(np.diag(uf.dot(rho_rm).dot(np.conj(np.transpose(uf)))))

## Constructing the X function for each unitary
qubits = NN # number of qubits, # qubit is the variable in this loop
probbe = probb

M = np.zeros((2**qubits, 2**qubits))
M = np.dot(probbe[:,None], probbe[None,:])

xor_mat = np.zeros((2**qubits, 2**qubits))
xor_mat = np.bitwise_xor(np.arange(2**qubits)[:,None],np.arange(2**qubits)[None,:])

temp = xor_mat
for ii in range(2**NN-1,0,-1):
xor_matt = np.where(temp == ii, bitcount[0,ii], temp)
temp = xor_matt
xor_matt =  np.where(xor_matt == 0, 1, xor_matt)   

X_temp = M*xor_matt

## final vector of the X function without shot noise
X[0,iu] = 2**(NN)*np.sum(X_temp.flatten())


return X[0,:]


## Randomized measurement realised in an experiment with shot noise
def RM_sn(NN, rho_rm, nu, nm, xi, phi):

bitcount = np.zeros((1,2**NN))
for ii in range(2**NN):
bitcount[:,ii] = (-2.)**(-countSetBits(ii))

## Interval of integration for the unitary angles \xi, \alpha and \psi
xi_b = 1
psi_b = 2*math.pi
alpha_b = 2*math.pi

## Vector of all the values of the function X with shot noise
X_sn = np.zeros((NN, nu))

partition_string_system = ['1'*x +'0'*(NN-x) for x in range(1,NN+1)]
partition_system = np.array([int(p,2) for p in partition_string_system])

for iu in range(nu):

probb = np.zeros((1, 2**NN))
uf = [1]
u_temp = 1j*(np.zeros((NN,2,2)))

for qubits in range(NN):

## preparing the unitary angles \alpha and \psi
alpha = 0
psi = 0
alpha = (-phi[qubits, iu])*alpha_b
psi = (phi[qubits,iu])*psi_b
u_temp[qubits,:,:] = (np.array([[math.sqrt(1-xi[qubits,iu])*cmath.exp(1j*alpha), math.sqrt(xi[qubits, iu])*cmath.exp(1j*psi)] , [-math.sqrt(xi[qubits, iu])*cmath.exp(-1j*psi), math.sqrt(1-xi[qubits, iu])*cmath.exp(-1j*alpha)]], dtype = complex))

## final unitary u = \otimes u_i 
uf = 1j*(np.kron(uf,u_temp[qubits,:,:]))

## probabilities obtained by performing the randomized measurements on \rho
probb = np.real(np.diag(uf.dot(rho_rm).dot(np.conj(np.transpose(uf)))))

## loading the bitstrings measured during the experiment
## here we sample them according to the bitstring probabilities
bit_strings[0,:] = random_gen.choice(range(2**NN), size = nm, p = probb) # bit strings measured as in an experiment for each random unitary applied to the qubits

# performing the xor operation for each of pair of the bitstring
xor_mat = np.bitwise_xor(bit_strings[0][:,None],bit_strings[0][None,:])

## constructing the hamming array
hamming_counts = np.bincount(xor_mat.flatten() & partition_system[NN-1])
X_temp = np.sum(np.multiply(hamming_counts,bitcount[:,0:len(hamming_counts)]))

## unbiasing the estimate obtained with nm measurements
X_sn[0,iu] = ((X_temp*2**(NN))/(nm*(nm-1))-2**(NN)/(nm-1))

return X_sn[0,:]

def RM_sn_RAM(NN, rho_rm, nu, nm, theta_2, theta_3):

# interval of integration for each angle
var_xi= xi_b*(theta_2) # parametrising phi and theta_2 to xi
X_e = np.zeros((1, nu))

bitcount = np.zeros((1,2**NN))
for ii in range(2**NN):
bitcount[:,ii] = (-2.)**(-countSetBits(ii))

#bit_strings = np.zeros((nu,nm), dtype = int16)
partition_string_system = ['1'*x +'0'*(NN-x) for x in range(1,NN+1)]
partition_system = np.array([int(p,2) for p in partition_string_system])


for iu in range(nu):
bit_strings = np.zeros((1,nm), dtype = int)
probb = np.zeros((1, 2**NN))
uf = [1]
u_temp = 1j*(np.zeros((NN,2,2)))

for qubits in range(NN):
alpha = 0
psi = 0
alpha = (-theta_3[qubits, iu])*alpha_b
psi = (theta_3[qubits,iu])*psi_b
u_temp[qubits,:,:] = (np.array([[math.sqrt(1-var_xi[qubits,iu])*cmath.exp(1j*alpha), math.sqrt(var_xi[qubits, iu])*cmath.exp(1j*psi)] , [-math.sqrt(var_xi[qubits, iu])*cmath.exp(-1j*psi), math.sqrt(1-var_xi[qubits, iu])*cmath.exp(-1j*alpha)]], dtype = complex))

uf = 1j*(np.kron(uf,u_temp[qubits,:,:]))

probb = np.real(np.diag(uf.dot(rho_rm).dot(np.conj(np.transpose(uf)))))

# loading the bitstrings measured during the experiment
bit_strings[0,:] = random_gen.choice(range(2**NN), size = nm, p = probb) # bit strings measured as in an experiment for each random unitary applied to the qubits
histto = (np.bincount(bit_strings[0,:])).astype(float64)
lenn = len(histto)
probbe = np.zeros(2**NN).astype(float)
for ii in range(2**NN):
probbe[ii] = np.count_nonzero(bit_strings == ii)               

M = np.zeros((2**NN, 2**NN))
M = np.dot(probbe[:,None], probbe[None,:])

xor_mat = np.zeros((2**NN, 2**NN))
xor_mat = np.bitwise_xor(np.arange(2**NN)[:,None],np.arange(2**NN)[None,:])

temp = xor_mat
for ii in range(2**NN-1,0,-1):
xor_matt = np.where(temp == ii, bitcount[0,ii], temp)
temp = xor_matt
xor_matt =  np.where(xor_matt == 0, 1, xor_matt)   

X_temp = np.sum(M*xor_matt)

#X_e[0,iu] = 2**(NN)*np.sum(X_temp.flatten())
#hamming = (-2)**(-1*(np.bitwise_xor(np.arange(0,2**NN,1)[:,None],np.arange(0,2**NN,1)[None,:]))).astype(float)
#probbb = np.dot(histto[:,None],histto[None,:]).astype(float64)
#print(probbb)
#X_temp = np.sum(np.multiply(hamming,probbb))

#X_e[0,iu] = np.sum(np.multiply
#for ii in range(2**NN):
#    histto[0,ii] = np.count_nonzeros(bit_strings == ii)
#probbb = histto.dot(histto.T)
# performing the xor operation for each of pair of the bitstring
#xor_mat = np.bitwise_xor(bit_strings[0][:,None],bit_strings[0][None,:])
#print(partition_system)
#for qubits in range(N):            
#hamming_counts = np.bincount(xor_mat.flatten() & partition_system[NN-1])
#X_temp = np.sum(np.multiply(hamming_counts,bitcount[:,0:len(hamming_counts)]))
X_e[0,iu] = ((X_temp*2**(NN))/(nm*(nm-1))-2**(NN)/(nm-1))

return X_e[0,:]
"""                                                                                                                                    
